

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="python" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="python" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>algs &mdash; Project2_Clustering 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Project2_Clustering
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Project2_Clustering</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">algs</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/autoapi/algs/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-algs">
<span id="algs"></span><h1><a class="reference internal" href="#module-algs" title="algs"><code class="xref py py-mod docutils literal notranslate"><span class="pre">algs</span></code></a><a class="headerlink" href="#module-algs" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#algs.HierarchicalClustering" title="algs.HierarchicalClustering"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HierarchicalClustering</span></code></a></p></td>
<td><p>This is a class is used to preform Hierarchial Clustering on a set of M observations by N features matrix.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#algs.PartitionClustering" title="algs.PartitionClustering"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PartitionClustering</span></code></a></p></td>
<td><p>This is a class is used to preform Partition Clustering on a set of M observations by N features matrix.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#algs.SilhouetteScore" title="algs.SilhouetteScore"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SilhouetteScore</span></code></a>(ClusteringObject)</p></td>
<td><p>Calculates the Silhouette Score of your Cluster.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#algs.TanimotoCoeff" title="algs.TanimotoCoeff"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TanimotoCoeff</span></code></a>(ClusterA, ClusterB)</p></td>
<td><p>Calculates the Tanimoto similarity Coefficent for two given clusters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#algs.CalculatePairWiseDistance" title="algs.CalculatePairWiseDistance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CalculatePairWiseDistance</span></code></a>(arr1, arr2)</p></td>
<td><p>Calculates the Euclidean distance between two observations on N based features.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt id="algs.SilhouetteScore">
<code class="sig-prename descclassname">algs.</code><code class="sig-name descname">SilhouetteScore</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ClusteringObject</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.SilhouetteScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Silhouette Score of your Cluster.
This score can be used to evaluate the quality of clusters created by the clustering algorithim. This will calcualte
the silhouette score for each observation/data point and return the mean of every point. The range of values
calculated and returned will be between [-1,1]. The algorithim will calcute for each point
a = Cohesion of each observation within a cluster
b = Seperation of each observation within other clusters
s(i) = b-a/max(a,b)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ClusteringObject</strong> (<em>object</em>) -- This can be either a HierarchicalClustering or a PartitionClustering object from algs class that has a filled ClusteringObject.clusters.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns the mean Silhouette score across all individuals observations, value will be between [-1,1]. A value
close to 1 will mean the clusters is well seperated and dense, 0 representing overlapping clusters, and -1 meaning
the samples might have been assigned to the wrong cluster.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="algs.TanimotoCoeff">
<code class="sig-prename descclassname">algs.</code><code class="sig-name descname">TanimotoCoeff</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ClusterA</span></em>, <em class="sig-param"><span class="n">ClusterB</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.TanimotoCoeff" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Tanimoto similarity Coefficent for two given clusters.
This is used to evaluate the similarity of one clustering compared to another clustering. The Tanimoto coefficient
is implemented the same way as Jacard Distance, since T. Tanimoto created this implementation independently from
Jaccard with the primary purpose for Cheminformatics. Caluclating this coefficeint will come from dividing the
intersection of the two sets from the union of both sets.
J(x,y)=|X insec Y|/<a href="#id1"><span class="problematic" id="id2">|X union Y|</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ClusterA</strong> (<em>list</em>) -- This can contain either a list of list where each list inside the main list represent a cluster.</p></li>
<li><p><strong>can be a list type</strong><strong> or </strong><strong>a numpy array where each row is a cluster.</strong> (<em>This</em>) -- ex: [[1,2,3],[4,5,6],[7,8]]</p></li>
<li><p><strong>ClusterB</strong> (<em>list</em>) -- Same as cluster A, make sure the type of list created is consistent and the same size as the first</p></li>
<li><p><strong>cluster.</strong> -- </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The range of this coefficient is between [0,1] with a value of 1 being identical clusters
and 0 having no identical matches found in the cluster.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="algs.CalculatePairWiseDistance">
<code class="sig-prename descclassname">algs.</code><code class="sig-name descname">CalculatePairWiseDistance</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">arr1</span></em>, <em class="sig-param"><span class="n">arr2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.CalculatePairWiseDistance" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Euclidean distance between two observations on N based features.
This utilizes vector operation so when you input the data be sure to input it as a singular dimension of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>arr1</strong> (<em>list</em>) -- 1-d array of data. ex [1,2,4,4,5]</p></li>
<li><p><strong>arr2</strong> (<em>list</em>) -- 1-d array of data. ex [2,5,6,3,1]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Single value of the euclidean distance between these two obsevations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="algs.HierarchicalClustering">
<em class="property">class </em><code class="sig-prename descclassname">algs.</code><code class="sig-name descname">HierarchicalClustering</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">rawdata</span></em>, <em class="sig-param"><span class="n">n_clusters</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.HierarchicalClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a class is used to preform Hierarchial Clustering on a set of M observations by N features matrix.
This type of clustering will be an Agglomerative clustering, or a bottom up approach, where we start off with each
node in thier own cluster, combining pairs clusters one iteration at a time until we get to a desired amount of
clusters to stop at. This is an implementation of a deterministic clustering algorithim</p>
<blockquote>
<div><dl class="simple">
<dt>Attributes:</dt><dd><p>rawdata (array-like): Matrix of M observation x N features, must be set so the row represents an individual observation
DistanceMatrix (array-like): Distance Matrix of [M x M] features where each index represents the euclidean distance
clusters(array-like): empty at initialization, stores a cluster array with each list inside the main list being a cluster of obvservations.
n_clusters(int): Specify the number of clusters we should stop our petitioning algorithim at.
clustersassignment(array-like): empty at initialization, stores an 1-d array of size M and stores the cluster ID each nodes belings to</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt id="algs.HierarchicalClustering.CalculateEuclideanDistance">
<code class="sig-name descname">CalculateEuclideanDistance</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.HierarchicalClustering.CalculateEuclideanDistance" title="Permalink to this definition">¶</a></dt>
<dd><p>This helper function will help fill the distance matrix needed for the HierarchicalClustering clustering
algorithim, this will iterate us though each observation calculating the Euclidean pairwise distance between the two obsevations.</p>
<blockquote>
<div><dl class="simple">
<dt>Returns:</dt><dd><p>self.DistanceMatrix(array-like): Distance Matrix of the object. Will now be non-empty array</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt id="algs.HierarchicalClustering.FitPreductions">
<code class="sig-name descname">FitPreductions</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.HierarchicalClustering.FitPreductions" title="Permalink to this definition">¶</a></dt>
<dd><p>This helper function will be used to fill self.clusterassignment, where we will go though each cluster and
assign each observation in that cluster a numerical label, The number of unique numerical label will be equal
to the n_clusters you define as a user.</p>
<p>example:
Input: [[1,2,3],[4,5],[6,7,8,9]]
Output: [1,1,1,2,2,3,3,3,3]</p>
</dd></dl>

<dl class="py method">
<dt id="algs.HierarchicalClustering.runClustering">
<code class="sig-name descname">runClustering</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.HierarchicalClustering.runClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to run my clustering algorithim. This will be a agglomerative clustering implementation.
A minor psudocode implementation of our alg will be:
1. Assign each node into their own cluster
while the length of cluster &gt; number of clusters desired
2. Find the smallest non.nan distance in the Distance Matrix
3 Combine the clusters where the distance is found
4. Update distance matrix we combine the distances of the two observations and prune a row/col.
done
5. Assign each observation thier clusterID</p>
<blockquote>
<div><dl class="simple">
<dt>Returns:</dt><dd><p>self.clusters (array-like): list of list of observations where each list represents a cluster and the observations found in that cluster
self.clusterassignment(array-like): Cluster assignment for each of the observation</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="algs.PartitionClustering">
<em class="property">class </em><code class="sig-prename descclassname">algs.</code><code class="sig-name descname">PartitionClustering</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">rawdata</span></em>, <em class="sig-param"><span class="n">n_clusters</span></em>, <em class="sig-param"><span class="n">max_iteration</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.PartitionClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a class is used to preform Partition Clustering on a set of M observations by N features matrix.
This type of clustering will be an Agglomerative clustering, or a bottom up approach, where we start off with
each node in thier own cluster, combining pairs clusters one iteration at a time until we get to a desired amount
of clusters to stop at. This is an implementation of a non-deterministic clustering algorithim</p>
<blockquote>
<div><dl class="simple">
<dt>Attributes:</dt><dd><p>rawdata (array-like): Matrix of M observation x N features, must be set so the row represents an individual observation
DistanceMatrix (array-like): Distance Matrix of [M x M] features where each index represents the euclidean distance
centroids(array-like): will hold the centoids value
max_iteration(int): Since the time to converge to a centroid is unknown this parameter is here to allow us to break after a certain amount of iterations
clusters(array-like): Empty at initialization, stores a cluster array with each list inside the main list being a cluster of obvservations.
n_clusters(int): Specify the number of clusters we should stop our petitioning algorithim at.
clustersassignment(array-like): empty at initialization, stores an 1-d array of size M and stores the cluster ID each nodes belings to</p>
</dd>
</dl>
</div></blockquote>
<dl class="py method">
<dt id="algs.PartitionClustering.UpdateCentroid">
<code class="sig-name descname">UpdateCentroid</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="n">new_cluster</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.PartitionClustering.UpdateCentroid" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used as a helper function of my run.clustering() function to identify the new Centroid.
This is used to take in the current clustering array, calculate the mean of each cluster, and assign the closet
point to the mean as the new centroid. I implemented a style choice of having the centroid be the observation closest
to the cluster mean rather then the cluster mean itself, while this is not the best Mathemetical implementation,
it allows us to ignore most edge cases when a updated centroid mean may produde and empty cluster. Also provides
a slightly faster implementation.</p>
<blockquote>
<div><dl class="simple">
<dt>Args:</dt><dd><p>new_cluster (array-like): current iteration of clusters assignments,</p>
</dd>
<dt>Returns:</dt><dd><p>self.centoid (array-like): this will return an updated version of centorid nodes</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt id="algs.PartitionClustering.FitPreductions">
<code class="sig-name descname">FitPreductions</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.PartitionClustering.FitPreductions" title="Permalink to this definition">¶</a></dt>
<dd><p>This helper function will be used to fill self.clusterassignment, where we will go though each cluster and
assign each observation in that cluster a numerical label, The number of unique numerical label will be equal
to the n_clusters you define as a user.</p>
<p>example:
Input: [[1,2,3],[4,5],[6,7,8,9]]</p>
<p>Output: [1,1,1,2,2,3,3,3,3]</p>
</dd></dl>

<dl class="py method">
<dt id="algs.PartitionClustering.runClustering">
<code class="sig-name descname">runClustering</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em><span class="sig-paren">)</span><a class="headerlink" href="#algs.PartitionClustering.runClustering" title="Permalink to this definition">¶</a></dt>
<dd><p>This function is used to run our clustering algorithim. This will be a k-means clustering implementation.
A light psudocode implementation of my alg will be:
1. Choose a random set of observations to be the initial centroids
while centroids have not converged or reached max_iterations:
2. Assign each observation to their closest cluster centroid
3  Update the centroid based off the mean of the newly assigned cluster
done
4. Assign each observation thier clusterID</p>
<blockquote>
<div><dl class="simple">
<dt>Returns:</dt><dd><p>self.clusters (array-like): list of list of observations where each list represents a cluster and the observations found in that cluster
self.clusterassignment(array-like): Cluster assignment for each of the observation</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Miguel Guardado

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>